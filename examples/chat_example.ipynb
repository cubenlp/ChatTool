{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat 对象使用示例\n",
    "\n",
    "这个示例展示了如何使用 Chat 对象进行对话管理，包括：\n",
    "- 从 .env 文件加载配置\n",
    "- 基本对话功能\n",
    "- 异步对话\n",
    "- 对话历史管理\n",
    "- 错误处理\n",
    "- 高级功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境准备和导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# 导入 chattool 相关模块\n",
    "from chattool.core.chattype import Chat\n",
    "from chattool.core.config import OpenAIConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 创建 Chat 对象\n",
    "\n",
    "使用环境变量自动配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chat 对象创建成功（使用环境变量配置）\n",
      "✅ Chat 对象创建成功（使用显式配置）\n"
     ]
    }
   ],
   "source": [
    "# 方法1: 使用默认配置（自动从环境变量读取）\n",
    "chat = Chat()\n",
    "print(\"✅ Chat 对象创建成功（使用环境变量配置）\")\n",
    "\n",
    "# 方法2: 使用显式配置\n",
    "config = OpenAIConfig(\n",
    "    api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    api_base=os.getenv('OPENAI_API_BASE'),\n",
    "    model=os.getenv('OPENAI_API_MODEL', 'gpt-3.5-turbo'),\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000\n",
    ")\n",
    "chat_with_config = Chat(config=config)\n",
    "print(\"✅ Chat 对象创建成功（使用显式配置）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 基本对话示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 第一轮对话 ===\n",
      "用户: 你好！请简单介绍一下自己。\n",
      "助手: 你好！我是一个由OpenAI开发的AI语言模型助手，旨在提供信息和回答问题，帮助你解决问题和获取知识。有什么我可以帮你的吗？\n",
      "Token使用: 76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 设置系统提示\n",
    "chat.system(\"你是一个友善的AI助手，请用简洁明了的方式回答问题。\")\n",
    "\n",
    "# 进行第一轮对话\n",
    "print(\"=== 第一轮对话 ===\")\n",
    "response1 = chat.user(\"你好！请简单介绍一下自己。\").get_response()\n",
    "print(f\"用户: 你好！请简单介绍一下自己。\")\n",
    "print(f\"助手: {response1.content}\")\n",
    "print(f\"Token使用: {response1.total_tokens}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 第二轮对话 ===\n",
      "用户: 能告诉我今天是星期几吗？\n",
      "助手: 抱歉，我无法实时访问互联网或日历，因此不能告诉你今天是星期几。不过，你可以通过你的手机、电脑或手表快速检查一下！\n",
      "Token使用: 126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 继续对话\n",
    "print(\"=== 第二轮对话 ===\")\n",
    "response2 = chat.user(\"能告诉我今天是星期几吗？\").get_response()\n",
    "print(f\"用户: 能告诉我今天是星期几吗？\")\n",
    "print(f\"助手: {response2.content}\")\n",
    "print(f\"Token使用: {response2.total_tokens}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 查看对话历史"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 对话历史 ===\n",
      "1. [SYSTEM]: 你是一个友善的AI助手，请用简洁明了的方式回答问题。\n",
      "2. [USER]: 你好！请简单介绍一下自己。\n",
      "3. [ASSISTANT]: 你好！我是一个由OpenAI开发的AI语言模型助手，旨在提供信息和回答问题，帮助你解决问题和获取知识。有什么我可以帮你的吗？\n",
      "4. [USER]: 能告诉我今天是星期几吗？\n",
      "5. [ASSISTANT]: 抱歉，我无法实时访问互联网或日历，因此不能告诉你今天是星期几。不过，你可以通过你的手机、电脑或手表快速检查一下！\n",
      "\n",
      "总消息数: 5\n",
      "最后一条消息: 抱歉，我无法实时访问互联网或日历，因此不能告诉你今天是星期几。不过，你可以通过你的手机、电脑或手表快速检查一下！\n"
     ]
    }
   ],
   "source": [
    "# 查看完整对话历史\n",
    "print(\"=== 对话历史 ===\")\n",
    "for i, message in enumerate(chat.chat_log):\n",
    "    role = message['role']\n",
    "    content = message['content'][:100] + '...' if len(message['content']) > 100 else message['content']\n",
    "    print(f\"{i+1}. [{role.upper()}]: {content}\")\n",
    "\n",
    "print(f\"\\n总消息数: {len(chat)}\")\n",
    "print(f\"最后一条消息: {chat.last_message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 便捷问答方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 便捷问答 ===\n",
      "问题: 请用一句话解释什么是人工智能？\n",
      "回答: 人工智能是一种通过计算机程序模拟人类智能的技术，用于执行任务如学习、推理、问题解决和语言理解。\n"
     ]
    }
   ],
   "source": [
    "# 使用 ask 方法进行快速问答\n",
    "print(\"=== 便捷问答 ===\")\n",
    "answer = chat.ask(\"请用一句话解释什么是人工智能？\")\n",
    "print(f\"问题: 请用一句话解释什么是人工智能？\")\n",
    "print(f\"回答: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 异步对话示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 异步对话示例 ===\n",
      "问题: Python中如何创建虚拟环境？\n",
      "回答: 在 Python 中，你可以使用 `venv` 模块来创建虚拟环境。以下是步骤：\n",
      "\n",
      "1. 打开你的终端或命令提示符。\n",
      "\n",
      "2. 导航到你想要创建虚拟环境的目录。\n",
      "\n",
      "3. 运行以下命令来创建虚拟环境：\n",
      "\n",
      "   ```bash\n",
      "   python -m venv myenv\n",
      "   ```\n",
      "\n",
      "   这里的 `myenv` 是你想要给虚拟环境取的名字。\n",
      "\n",
      "4. 激活虚拟环境：\n",
      "\n",
      "   - 在 Windows 上，使用：\n",
      "\n",
      "     ```bash\n",
      "     myenv\\Scripts\\activate\n",
      "     ```\n",
      "\n",
      "   - 在 macOS 和 Linux 上，使用：\n",
      "\n",
      "     ```bash\n",
      "     source myenv/bin/activate\n",
      "     ```\n",
      "\n",
      "5. 激活后，你可以在虚拟环境中安装包，包会与全局的 Python 安装隔离。安装包时使用：\n",
      "\n",
      "   ```bash\n",
      "   pip install package_name\n",
      "   ```\n",
      "\n",
      "6. 如果你要退出虚拟环境，使用：\n",
      "\n",
      "   ```bash\n",
      "   deactivate\n",
      "   ```\n",
      "\n",
      "这样，你就成功创建和管理了一个 Python 虚拟环境。\n"
     ]
    }
   ],
   "source": [
    "# 异步对话函数\n",
    "async def async_chat_example():\n",
    "    print(\"=== 异步对话示例 ===\")\n",
    "    \n",
    "    # 创建新的对话实例\n",
    "    async_chat = Chat()\n",
    "    async_chat.system(\"你是一个编程助手，请提供简洁的编程建议。\")\n",
    "    \n",
    "    # 异步获取响应\n",
    "    response = await async_chat.async_ask(\"Python中如何创建虚拟环境？\")\n",
    "    print(f\"问题: Python中如何创建虚拟环境？\")\n",
    "    print(f\"回答: {response}\")\n",
    "    \n",
    "    return async_chat\n",
    "\n",
    "# 运行异步示例\n",
    "async_chat = await async_chat_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 批量异步处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量处理多个问题\n",
    "async def batch_questions():\n",
    "    print(\"=== 批量异步处理 ===\")\n",
    "    \n",
    "    questions = [\n",
    "        \"什么是机器学习？\",\n",
    "        \"什么是深度学习？\",\n",
    "        \"什么是神经网络？\"\n",
    "    ]\n",
    "    \n",
    "    # 为每个问题创建独立的对话\n",
    "    tasks = []\n",
    "    for question in questions:\n",
    "        temp_chat = Chat()\n",
    "        temp_chat.system(\"请用一句话简洁回答问题。\")\n",
    "        task = temp_chat.async_ask(question)\n",
    "        tasks.append((question, task))\n",
    "    \n",
    "    # 并发执行所有任务\n",
    "    for i, (question, task) in enumerate(tasks):\n",
    "        answer = await task\n",
    "        print(f\"{i+1}. 问题: {question}\")\n",
    "        print(f\"   回答: {answer}\")\n",
    "        print()\n",
    "\n",
    "await batch_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 对话管理功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对话复制\n",
    "print(\"=== 对话管理 ===\")\n",
    "copied_chat = chat.copy()\n",
    "print(f\"原对话消息数: {len(chat)}\")\n",
    "print(f\"复制对话消息数: {len(copied_chat)}\")\n",
    "\n",
    "# 在复制的对话中尝试不同的问题\n",
    "copied_response = copied_chat.ask(\"换个话题，你能推荐一本好书吗？\")\n",
    "print(f\"\\n复制对话中的新回答: {copied_response}\")\n",
    "\n",
    "# 删除最后一条消息\n",
    "removed_message = chat.pop()\n",
    "print(f\"\\n删除的消息: {removed_message}\")\n",
    "print(f\"删除后消息数: {len(chat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 对话持久化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存对话到文件\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "filename = f\"conversation_{timestamp}.jsonl\"\n",
    "\n",
    "print(\"=== 对话持久化 ===\")\n",
    "chat.save(filename)\n",
    "print(f\"✅ 对话已保存到: {filename}\")\n",
    "\n",
    "# 从文件加载对话\n",
    "loaded_chat = Chat.load(filename)\n",
    "print(f\"✅ 从文件加载对话，消息数: {len(loaded_chat)}\")\n",
    "\n",
    "# 继续加载的对话\n",
    "continue_response = loaded_chat.ask(\"我们刚才聊到哪里了？\")\n",
    "print(f\"继续对话: {continue_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 错误处理示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 错误处理示例\n",
    "def safe_chat_example():\n",
    "    print(\"=== 错误处理示例 ===\")\n",
    "    \n",
    "    try:\n",
    "        # 创建一个可能失败的请求\n",
    "        test_chat = Chat()\n",
    "        response = test_chat.user(\"测试消息\").get_response(\n",
    "            max_retries=2,\n",
    "            retry_delay=1.0\n",
    "        )\n",
    "        print(f\"✅ 请求成功: {response.content[:50]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 请求失败: {e}\")\n",
    "        \n",
    "        # 检查是否是API错误\n",
    "        if hasattr(e, 'response'):\n",
    "            print(f\"状态码: {e.response.status_code}\")\n",
    "            print(f\"错误详情: {e.response.text[:100]}...\")\n",
    "\n",
    "safe_chat_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 高级配置示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高级配置示例\n",
    "print(\"=== 高级配置示例 ===\")\n",
    "\n",
    "advanced_config = OpenAIConfig(\n",
    "    api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    api_base=os.getenv('OPENAI_API_BASE'),\n",
    "    model=os.getenv('OPENAI_API_MODEL', 'gpt-3.5-turbo'),\n",
    "    temperature=0.3,  # 更保守的温度\n",
    "    max_tokens=500,   # 限制输出长度\n",
    "    top_p=0.9,\n",
    "    frequency_penalty=0.1,\n",
    "    presence_penalty=0.1,\n",
    "    timeout=30.0,\n",
    "    max_retries=3,\n",
    "    retry_delay=2.0\n",
    ")\n",
    "\n",
    "advanced_chat = Chat(config=advanced_config)\n",
    "advanced_chat.system(\"你是一个精确的技术文档助手，请提供准确简洁的回答。\")\n",
    "\n",
    "response = advanced_chat.ask(\"请解释RESTful API的核心原则\")\n",
    "print(f\"高级配置回答: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 调试和监控"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调试信息\n",
    "print(\"=== 调试和监控 ===\")\n",
    "\n",
    "# 打印对话历史\n",
    "print(\"对话历史:\")\n",
    "chat.print_log()\n",
    "\n",
    "# 获取最后一次响应的详细信息\n",
    "if chat.last_response:\n",
    "    print(\"\\n最后一次响应详情:\")\n",
    "    print(f\"ID: {chat.last_response.id}\")\n",
    "    print(f\"模型: {chat.last_response.model}\")\n",
    "    print(f\"创建时间: {chat.last_response.created}\")\n",
    "    print(f\"完成原因: {chat.last_response.finish_reason}\")\n",
    "    print(f\"Token统计: {chat.last_response.usage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 清理资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理临时文件\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(\"=== 清理资源 ===\")\n",
    "\n",
    "# 清理生成的对话文件\n",
    "conversation_files = glob.glob(\"conversation_*.jsonl\")\n",
    "for file in conversation_files:\n",
    "    try:\n",
    "        os.remove(file)\n",
    "        print(f\"✅ 已删除: {file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 删除失败 {file}: {e}\")\n",
    "\n",
    "print(\"\\n🎉 示例演示完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "这个示例展示了 Chat 对象的主要功能：\n",
    "\n",
    "1. **环境配置**: 从 `.env` 文件加载配置\n",
    "2. **基本对话**: 同步和异步对话\n",
    "3. **消息管理**: 添加、查看、删除消息\n",
    "4. **批量处理**: 并发处理多个问题\n",
    "5. **对话管理**: 复制、保存、加载对话\n",
    "6. **错误处理**: 重试机制和异常处理\n",
    "7. **高级配置**: 自定义参数和行为\n",
    "8. **调试监控**: 查看详细信息和统计\n",
    "\n",
    "### 最佳实践\n",
    "\n",
    "- 使用环境变量管理敏感配置\n",
    "- 适当的错误处理和重试机制\n",
    "- 定期保存重要对话\n",
    "- 在高并发场景使用异步方法\n",
    "- 监控 token 使用情况\n",
    "\n",
    "### 下一步\n",
    "\n",
    "- 尝试不同的模型和参数\n",
    "- 集成到实际项目中\n",
    "- 探索函数调用功能\n",
    "- 实现自定义的对话流程"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
