{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat å¯¹è±¡ä½¿ç”¨ç¤ºä¾‹\n",
    "\n",
    "è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Chat å¯¹è±¡è¿›è¡Œå¯¹è¯ç®¡ç†ï¼ŒåŒ…æ‹¬ï¼š\n",
    "- ä» .env æ–‡ä»¶åŠ è½½é…ç½®\n",
    "- åŸºæœ¬å¯¹è¯åŠŸèƒ½\n",
    "- å¼‚æ­¥å¯¹è¯\n",
    "- å¯¹è¯å†å²ç®¡ç†\n",
    "- é”™è¯¯å¤„ç†\n",
    "- é«˜çº§åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒå‡†å¤‡å’Œå¯¼å…¥æ¨¡å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# å¯¼å…¥ chattool ç›¸å…³æ¨¡å—\n",
    "from chattool.core.chattype import Chat\n",
    "from chattool.core.config import OpenAIConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. åˆ›å»º Chat å¯¹è±¡\n",
    "\n",
    "ä½¿ç”¨ç¯å¢ƒå˜é‡è‡ªåŠ¨é…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chat å¯¹è±¡åˆ›å»ºæˆåŠŸï¼ˆä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®ï¼‰\n",
      "âœ… Chat å¯¹è±¡åˆ›å»ºæˆåŠŸï¼ˆä½¿ç”¨æ˜¾å¼é…ç½®ï¼‰\n"
     ]
    }
   ],
   "source": [
    "# æ–¹æ³•1: ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆè‡ªåŠ¨ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰\n",
    "chat = Chat()\n",
    "print(\"âœ… Chat å¯¹è±¡åˆ›å»ºæˆåŠŸï¼ˆä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®ï¼‰\")\n",
    "\n",
    "# æ–¹æ³•2: ä½¿ç”¨æ˜¾å¼é…ç½®\n",
    "config = OpenAIConfig(\n",
    "    api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    api_base=os.getenv('OPENAI_API_BASE'),\n",
    "    model=os.getenv('OPENAI_API_MODEL', 'gpt-3.5-turbo'),\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000\n",
    ")\n",
    "chat_with_config = Chat(config=config)\n",
    "print(\"âœ… Chat å¯¹è±¡åˆ›å»ºæˆåŠŸï¼ˆä½¿ç”¨æ˜¾å¼é…ç½®ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. åŸºæœ¬å¯¹è¯ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ç¬¬ä¸€è½®å¯¹è¯ ===\n",
      "ç”¨æˆ·: ä½ å¥½ï¼è¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚\n",
      "åŠ©æ‰‹: ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªç”±OpenAIå¼€å‘çš„AIè¯­è¨€æ¨¡å‹åŠ©æ‰‹ï¼Œæ—¨åœ¨æä¾›ä¿¡æ¯å’Œå›ç­”é—®é¢˜ï¼Œå¸®åŠ©ä½ è§£å†³é—®é¢˜å’Œè·å–çŸ¥è¯†ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ\n",
      "Tokenä½¿ç”¨: 76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# è®¾ç½®ç³»ç»Ÿæç¤º\n",
    "chat.system(\"ä½ æ˜¯ä¸€ä¸ªå‹å–„çš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ç®€æ´æ˜äº†çš„æ–¹å¼å›ç­”é—®é¢˜ã€‚\")\n",
    "\n",
    "# è¿›è¡Œç¬¬ä¸€è½®å¯¹è¯\n",
    "print(\"=== ç¬¬ä¸€è½®å¯¹è¯ ===\")\n",
    "response1 = chat.user(\"ä½ å¥½ï¼è¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚\").get_response()\n",
    "print(f\"ç”¨æˆ·: ä½ å¥½ï¼è¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚\")\n",
    "print(f\"åŠ©æ‰‹: {response1.content}\")\n",
    "print(f\"Tokenä½¿ç”¨: {response1.total_tokens}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ç¬¬äºŒè½®å¯¹è¯ ===\n",
      "ç”¨æˆ·: èƒ½å‘Šè¯‰æˆ‘ä»Šå¤©æ˜¯æ˜ŸæœŸå‡ å—ï¼Ÿ\n",
      "åŠ©æ‰‹: æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å®æ—¶è®¿é—®äº’è”ç½‘æˆ–æ—¥å†ï¼Œå› æ­¤ä¸èƒ½å‘Šè¯‰ä½ ä»Šå¤©æ˜¯æ˜ŸæœŸå‡ ã€‚ä¸è¿‡ï¼Œä½ å¯ä»¥é€šè¿‡ä½ çš„æ‰‹æœºã€ç”µè„‘æˆ–æ‰‹è¡¨å¿«é€Ÿæ£€æŸ¥ä¸€ä¸‹ï¼\n",
      "Tokenä½¿ç”¨: 126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ç»§ç»­å¯¹è¯\n",
    "print(\"=== ç¬¬äºŒè½®å¯¹è¯ ===\")\n",
    "response2 = chat.user(\"èƒ½å‘Šè¯‰æˆ‘ä»Šå¤©æ˜¯æ˜ŸæœŸå‡ å—ï¼Ÿ\").get_response()\n",
    "print(f\"ç”¨æˆ·: èƒ½å‘Šè¯‰æˆ‘ä»Šå¤©æ˜¯æ˜ŸæœŸå‡ å—ï¼Ÿ\")\n",
    "print(f\"åŠ©æ‰‹: {response2.content}\")\n",
    "print(f\"Tokenä½¿ç”¨: {response2.total_tokens}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æŸ¥çœ‹å¯¹è¯å†å²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== å¯¹è¯å†å² ===\n",
      "1. [SYSTEM]: ä½ æ˜¯ä¸€ä¸ªå‹å–„çš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ç®€æ´æ˜äº†çš„æ–¹å¼å›ç­”é—®é¢˜ã€‚\n",
      "2. [USER]: ä½ å¥½ï¼è¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚\n",
      "3. [ASSISTANT]: ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªç”±OpenAIå¼€å‘çš„AIè¯­è¨€æ¨¡å‹åŠ©æ‰‹ï¼Œæ—¨åœ¨æä¾›ä¿¡æ¯å’Œå›ç­”é—®é¢˜ï¼Œå¸®åŠ©ä½ è§£å†³é—®é¢˜å’Œè·å–çŸ¥è¯†ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ\n",
      "4. [USER]: èƒ½å‘Šè¯‰æˆ‘ä»Šå¤©æ˜¯æ˜ŸæœŸå‡ å—ï¼Ÿ\n",
      "5. [ASSISTANT]: æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å®æ—¶è®¿é—®äº’è”ç½‘æˆ–æ—¥å†ï¼Œå› æ­¤ä¸èƒ½å‘Šè¯‰ä½ ä»Šå¤©æ˜¯æ˜ŸæœŸå‡ ã€‚ä¸è¿‡ï¼Œä½ å¯ä»¥é€šè¿‡ä½ çš„æ‰‹æœºã€ç”µè„‘æˆ–æ‰‹è¡¨å¿«é€Ÿæ£€æŸ¥ä¸€ä¸‹ï¼\n",
      "\n",
      "æ€»æ¶ˆæ¯æ•°: 5\n",
      "æœ€åä¸€æ¡æ¶ˆæ¯: æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å®æ—¶è®¿é—®äº’è”ç½‘æˆ–æ—¥å†ï¼Œå› æ­¤ä¸èƒ½å‘Šè¯‰ä½ ä»Šå¤©æ˜¯æ˜ŸæœŸå‡ ã€‚ä¸è¿‡ï¼Œä½ å¯ä»¥é€šè¿‡ä½ çš„æ‰‹æœºã€ç”µè„‘æˆ–æ‰‹è¡¨å¿«é€Ÿæ£€æŸ¥ä¸€ä¸‹ï¼\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹å®Œæ•´å¯¹è¯å†å²\n",
    "print(\"=== å¯¹è¯å†å² ===\")\n",
    "for i, message in enumerate(chat.chat_log):\n",
    "    role = message['role']\n",
    "    content = message['content'][:100] + '...' if len(message['content']) > 100 else message['content']\n",
    "    print(f\"{i+1}. [{role.upper()}]: {content}\")\n",
    "\n",
    "print(f\"\\næ€»æ¶ˆæ¯æ•°: {len(chat)}\")\n",
    "print(f\"æœ€åä¸€æ¡æ¶ˆæ¯: {chat.last_message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ä¾¿æ·é—®ç­”æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ä¾¿æ·é—®ç­” ===\n",
      "é—®é¢˜: è¯·ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ\n",
      "å›ç­”: äººå·¥æ™ºèƒ½æ˜¯ä¸€ç§é€šè¿‡è®¡ç®—æœºç¨‹åºæ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„æŠ€æœ¯ï¼Œç”¨äºæ‰§è¡Œä»»åŠ¡å¦‚å­¦ä¹ ã€æ¨ç†ã€é—®é¢˜è§£å†³å’Œè¯­è¨€ç†è§£ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨ ask æ–¹æ³•è¿›è¡Œå¿«é€Ÿé—®ç­”\n",
    "print(\"=== ä¾¿æ·é—®ç­” ===\")\n",
    "answer = chat.ask(\"è¯·ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ\")\n",
    "print(f\"é—®é¢˜: è¯·ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ\")\n",
    "print(f\"å›ç­”: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. å¼‚æ­¥å¯¹è¯ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== å¼‚æ­¥å¯¹è¯ç¤ºä¾‹ ===\n",
      "é—®é¢˜: Pythonä¸­å¦‚ä½•åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼Ÿ\n",
      "å›ç­”: åœ¨ Python ä¸­ï¼Œä½ å¯ä»¥ä½¿ç”¨ `venv` æ¨¡å—æ¥åˆ›å»ºè™šæ‹Ÿç¯å¢ƒã€‚ä»¥ä¸‹æ˜¯æ­¥éª¤ï¼š\n",
      "\n",
      "1. æ‰“å¼€ä½ çš„ç»ˆç«¯æˆ–å‘½ä»¤æç¤ºç¬¦ã€‚\n",
      "\n",
      "2. å¯¼èˆªåˆ°ä½ æƒ³è¦åˆ›å»ºè™šæ‹Ÿç¯å¢ƒçš„ç›®å½•ã€‚\n",
      "\n",
      "3. è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼š\n",
      "\n",
      "   ```bash\n",
      "   python -m venv myenv\n",
      "   ```\n",
      "\n",
      "   è¿™é‡Œçš„ `myenv` æ˜¯ä½ æƒ³è¦ç»™è™šæ‹Ÿç¯å¢ƒå–çš„åå­—ã€‚\n",
      "\n",
      "4. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼š\n",
      "\n",
      "   - åœ¨ Windows ä¸Šï¼Œä½¿ç”¨ï¼š\n",
      "\n",
      "     ```bash\n",
      "     myenv\\Scripts\\activate\n",
      "     ```\n",
      "\n",
      "   - åœ¨ macOS å’Œ Linux ä¸Šï¼Œä½¿ç”¨ï¼š\n",
      "\n",
      "     ```bash\n",
      "     source myenv/bin/activate\n",
      "     ```\n",
      "\n",
      "5. æ¿€æ´»åï¼Œä½ å¯ä»¥åœ¨è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…åŒ…ï¼ŒåŒ…ä¼šä¸å…¨å±€çš„ Python å®‰è£…éš”ç¦»ã€‚å®‰è£…åŒ…æ—¶ä½¿ç”¨ï¼š\n",
      "\n",
      "   ```bash\n",
      "   pip install package_name\n",
      "   ```\n",
      "\n",
      "6. å¦‚æœä½ è¦é€€å‡ºè™šæ‹Ÿç¯å¢ƒï¼Œä½¿ç”¨ï¼š\n",
      "\n",
      "   ```bash\n",
      "   deactivate\n",
      "   ```\n",
      "\n",
      "è¿™æ ·ï¼Œä½ å°±æˆåŠŸåˆ›å»ºå’Œç®¡ç†äº†ä¸€ä¸ª Python è™šæ‹Ÿç¯å¢ƒã€‚\n"
     ]
    }
   ],
   "source": [
    "# å¼‚æ­¥å¯¹è¯å‡½æ•°\n",
    "async def async_chat_example():\n",
    "    print(\"=== å¼‚æ­¥å¯¹è¯ç¤ºä¾‹ ===\")\n",
    "    \n",
    "    # åˆ›å»ºæ–°çš„å¯¹è¯å®ä¾‹\n",
    "    async_chat = Chat()\n",
    "    async_chat.system(\"ä½ æ˜¯ä¸€ä¸ªç¼–ç¨‹åŠ©æ‰‹ï¼Œè¯·æä¾›ç®€æ´çš„ç¼–ç¨‹å»ºè®®ã€‚\")\n",
    "    \n",
    "    # å¼‚æ­¥è·å–å“åº”\n",
    "    response = await async_chat.async_ask(\"Pythonä¸­å¦‚ä½•åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼Ÿ\")\n",
    "    print(f\"é—®é¢˜: Pythonä¸­å¦‚ä½•åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼Ÿ\")\n",
    "    print(f\"å›ç­”: {response}\")\n",
    "    \n",
    "    return async_chat\n",
    "\n",
    "# è¿è¡Œå¼‚æ­¥ç¤ºä¾‹\n",
    "async_chat = await async_chat_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. æ‰¹é‡å¼‚æ­¥å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¹é‡å¤„ç†å¤šä¸ªé—®é¢˜\n",
    "async def batch_questions():\n",
    "    print(\"=== æ‰¹é‡å¼‚æ­¥å¤„ç† ===\")\n",
    "    \n",
    "    questions = [\n",
    "        \"ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ\",\n",
    "        \"ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ\",\n",
    "        \"ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œï¼Ÿ\"\n",
    "    ]\n",
    "    \n",
    "    # ä¸ºæ¯ä¸ªé—®é¢˜åˆ›å»ºç‹¬ç«‹çš„å¯¹è¯\n",
    "    tasks = []\n",
    "    for question in questions:\n",
    "        temp_chat = Chat()\n",
    "        temp_chat.system(\"è¯·ç”¨ä¸€å¥è¯ç®€æ´å›ç­”é—®é¢˜ã€‚\")\n",
    "        task = temp_chat.async_ask(question)\n",
    "        tasks.append((question, task))\n",
    "    \n",
    "    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡\n",
    "    for i, (question, task) in enumerate(tasks):\n",
    "        answer = await task\n",
    "        print(f\"{i+1}. é—®é¢˜: {question}\")\n",
    "        print(f\"   å›ç­”: {answer}\")\n",
    "        print()\n",
    "\n",
    "await batch_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. å¯¹è¯ç®¡ç†åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹è¯å¤åˆ¶\n",
    "print(\"=== å¯¹è¯ç®¡ç† ===\")\n",
    "copied_chat = chat.copy()\n",
    "print(f\"åŸå¯¹è¯æ¶ˆæ¯æ•°: {len(chat)}\")\n",
    "print(f\"å¤åˆ¶å¯¹è¯æ¶ˆæ¯æ•°: {len(copied_chat)}\")\n",
    "\n",
    "# åœ¨å¤åˆ¶çš„å¯¹è¯ä¸­å°è¯•ä¸åŒçš„é—®é¢˜\n",
    "copied_response = copied_chat.ask(\"æ¢ä¸ªè¯é¢˜ï¼Œä½ èƒ½æ¨èä¸€æœ¬å¥½ä¹¦å—ï¼Ÿ\")\n",
    "print(f\"\\nå¤åˆ¶å¯¹è¯ä¸­çš„æ–°å›ç­”: {copied_response}\")\n",
    "\n",
    "# åˆ é™¤æœ€åä¸€æ¡æ¶ˆæ¯\n",
    "removed_message = chat.pop()\n",
    "print(f\"\\nåˆ é™¤çš„æ¶ˆæ¯: {removed_message}\")\n",
    "print(f\"åˆ é™¤åæ¶ˆæ¯æ•°: {len(chat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. å¯¹è¯æŒä¹…åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜å¯¹è¯åˆ°æ–‡ä»¶\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "filename = f\"conversation_{timestamp}.jsonl\"\n",
    "\n",
    "print(\"=== å¯¹è¯æŒä¹…åŒ– ===\")\n",
    "chat.save(filename)\n",
    "print(f\"âœ… å¯¹è¯å·²ä¿å­˜åˆ°: {filename}\")\n",
    "\n",
    "# ä»æ–‡ä»¶åŠ è½½å¯¹è¯\n",
    "loaded_chat = Chat.load(filename)\n",
    "print(f\"âœ… ä»æ–‡ä»¶åŠ è½½å¯¹è¯ï¼Œæ¶ˆæ¯æ•°: {len(loaded_chat)}\")\n",
    "\n",
    "# ç»§ç»­åŠ è½½çš„å¯¹è¯\n",
    "continue_response = loaded_chat.ask(\"æˆ‘ä»¬åˆšæ‰èŠåˆ°å“ªé‡Œäº†ï¼Ÿ\")\n",
    "print(f\"ç»§ç»­å¯¹è¯: {continue_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. é”™è¯¯å¤„ç†ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é”™è¯¯å¤„ç†ç¤ºä¾‹\n",
    "def safe_chat_example():\n",
    "    print(\"=== é”™è¯¯å¤„ç†ç¤ºä¾‹ ===\")\n",
    "    \n",
    "    try:\n",
    "        # åˆ›å»ºä¸€ä¸ªå¯èƒ½å¤±è´¥çš„è¯·æ±‚\n",
    "        test_chat = Chat()\n",
    "        response = test_chat.user(\"æµ‹è¯•æ¶ˆæ¯\").get_response(\n",
    "            max_retries=2,\n",
    "            retry_delay=1.0\n",
    "        )\n",
    "        print(f\"âœ… è¯·æ±‚æˆåŠŸ: {response.content[:50]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¯·æ±‚å¤±è´¥: {e}\")\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦æ˜¯APIé”™è¯¯\n",
    "        if hasattr(e, 'response'):\n",
    "            print(f\"çŠ¶æ€ç : {e.response.status_code}\")\n",
    "            print(f\"é”™è¯¯è¯¦æƒ…: {e.response.text[:100]}...\")\n",
    "\n",
    "safe_chat_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. é«˜çº§é…ç½®ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é«˜çº§é…ç½®ç¤ºä¾‹\n",
    "print(\"=== é«˜çº§é…ç½®ç¤ºä¾‹ ===\")\n",
    "\n",
    "advanced_config = OpenAIConfig(\n",
    "    api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    api_base=os.getenv('OPENAI_API_BASE'),\n",
    "    model=os.getenv('OPENAI_API_MODEL', 'gpt-3.5-turbo'),\n",
    "    temperature=0.3,  # æ›´ä¿å®ˆçš„æ¸©åº¦\n",
    "    max_tokens=500,   # é™åˆ¶è¾“å‡ºé•¿åº¦\n",
    "    top_p=0.9,\n",
    "    frequency_penalty=0.1,\n",
    "    presence_penalty=0.1,\n",
    "    timeout=30.0,\n",
    "    max_retries=3,\n",
    "    retry_delay=2.0\n",
    ")\n",
    "\n",
    "advanced_chat = Chat(config=advanced_config)\n",
    "advanced_chat.system(\"ä½ æ˜¯ä¸€ä¸ªç²¾ç¡®çš„æŠ€æœ¯æ–‡æ¡£åŠ©æ‰‹ï¼Œè¯·æä¾›å‡†ç¡®ç®€æ´çš„å›ç­”ã€‚\")\n",
    "\n",
    "response = advanced_chat.ask(\"è¯·è§£é‡ŠRESTful APIçš„æ ¸å¿ƒåŸåˆ™\")\n",
    "print(f\"é«˜çº§é…ç½®å›ç­”: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. è°ƒè¯•å’Œç›‘æ§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è°ƒè¯•ä¿¡æ¯\n",
    "print(\"=== è°ƒè¯•å’Œç›‘æ§ ===\")\n",
    "\n",
    "# æ‰“å°å¯¹è¯å†å²\n",
    "print(\"å¯¹è¯å†å²:\")\n",
    "chat.print_log()\n",
    "\n",
    "# è·å–æœ€åä¸€æ¬¡å“åº”çš„è¯¦ç»†ä¿¡æ¯\n",
    "if chat.last_response:\n",
    "    print(\"\\næœ€åä¸€æ¬¡å“åº”è¯¦æƒ…:\")\n",
    "    print(f\"ID: {chat.last_response.id}\")\n",
    "    print(f\"æ¨¡å‹: {chat.last_response.model}\")\n",
    "    print(f\"åˆ›å»ºæ—¶é—´: {chat.last_response.created}\")\n",
    "    print(f\"å®ŒæˆåŸå› : {chat.last_response.finish_reason}\")\n",
    "    print(f\"Tokenç»Ÿè®¡: {chat.last_response.usage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. æ¸…ç†èµ„æº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸…ç†ä¸´æ—¶æ–‡ä»¶\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(\"=== æ¸…ç†èµ„æº ===\")\n",
    "\n",
    "# æ¸…ç†ç”Ÿæˆçš„å¯¹è¯æ–‡ä»¶\n",
    "conversation_files = glob.glob(\"conversation_*.jsonl\")\n",
    "for file in conversation_files:\n",
    "    try:\n",
    "        os.remove(file)\n",
    "        print(f\"âœ… å·²åˆ é™¤: {file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ åˆ é™¤å¤±è´¥ {file}: {e}\")\n",
    "\n",
    "print(\"\\nğŸ‰ ç¤ºä¾‹æ¼”ç¤ºå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "\n",
    "è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº† Chat å¯¹è±¡çš„ä¸»è¦åŠŸèƒ½ï¼š\n",
    "\n",
    "1. **ç¯å¢ƒé…ç½®**: ä» `.env` æ–‡ä»¶åŠ è½½é…ç½®\n",
    "2. **åŸºæœ¬å¯¹è¯**: åŒæ­¥å’Œå¼‚æ­¥å¯¹è¯\n",
    "3. **æ¶ˆæ¯ç®¡ç†**: æ·»åŠ ã€æŸ¥çœ‹ã€åˆ é™¤æ¶ˆæ¯\n",
    "4. **æ‰¹é‡å¤„ç†**: å¹¶å‘å¤„ç†å¤šä¸ªé—®é¢˜\n",
    "5. **å¯¹è¯ç®¡ç†**: å¤åˆ¶ã€ä¿å­˜ã€åŠ è½½å¯¹è¯\n",
    "6. **é”™è¯¯å¤„ç†**: é‡è¯•æœºåˆ¶å’Œå¼‚å¸¸å¤„ç†\n",
    "7. **é«˜çº§é…ç½®**: è‡ªå®šä¹‰å‚æ•°å’Œè¡Œä¸º\n",
    "8. **è°ƒè¯•ç›‘æ§**: æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯å’Œç»Ÿè®¡\n",
    "\n",
    "### æœ€ä½³å®è·µ\n",
    "\n",
    "- ä½¿ç”¨ç¯å¢ƒå˜é‡ç®¡ç†æ•æ„Ÿé…ç½®\n",
    "- é€‚å½“çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶\n",
    "- å®šæœŸä¿å­˜é‡è¦å¯¹è¯\n",
    "- åœ¨é«˜å¹¶å‘åœºæ™¯ä½¿ç”¨å¼‚æ­¥æ–¹æ³•\n",
    "- ç›‘æ§ token ä½¿ç”¨æƒ…å†µ\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "- å°è¯•ä¸åŒçš„æ¨¡å‹å’Œå‚æ•°\n",
    "- é›†æˆåˆ°å®é™…é¡¹ç›®ä¸­\n",
    "- æ¢ç´¢å‡½æ•°è°ƒç”¨åŠŸèƒ½\n",
    "- å®ç°è‡ªå®šä¹‰çš„å¯¹è¯æµç¨‹"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
