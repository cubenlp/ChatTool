{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f786bd51",
   "metadata": {},
   "source": [
    "# ChatTool 基础使用指南\n",
    "\n",
    "本示例介绍 ChatTool 的三个核心功能：\n",
    "1. 配置密钥\n",
    "2. 基础对话\n",
    "3. 批量对话"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0486bd23",
   "metadata": {},
   "source": [
    "## 1. 配置密钥\n",
    "\n",
    "ChatTool 提供了统一的配置管理接口 `OpenAIConfig`。你可以通过它查看或修改 API 配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18323665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chattool import debug_log\n",
    "debug_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd162ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current API Key: sk-n3Qws***************************************7e8f2073\n",
      "Current Base URL: https://4.0.wokaai.com/v1\n",
      "Current Base URL: gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "from chattool import OpenAIConfig, Chat\n",
    "\n",
    "# 查看当前配置（自动从环境变量或 .env 文件读取）\n",
    "print(f\"Current API Key: {OpenAIConfig.OPENAI_API_KEY.mask_value()}\")\n",
    "print(f\"Current Base URL: {OpenAIConfig.OPENAI_API_BASE.value}\")\n",
    "print(f\"Current Base URL: {OpenAIConfig.OPENAI_API_MODEL.value}\")\n",
    "\n",
    "# 如果需要动态修改配置\n",
    "# OpenAIConfig.OPENAI_API_KEY.value = \"sk-new-key...\"\n",
    "# OpenAIConfig.OPENAI_API_BASE.value = \"https://api.openai-proxy.com/v1\"\n",
    "# OpenAIConfig.OPENAI_API_MODEL.value = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431a4f8d",
   "metadata": {},
   "source": [
    "## 2. 基础对话\n",
    "\n",
    "使用 `Chat` 对象进行单轮或多轮对话。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04b49f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "简单问答: 1 + 1 = 2\n",
      "\n",
      "用户: 斐波那契数列的前3个数是？\n",
      "助手: 斐波那契数列的前3个数是：1、1、2。\n",
      "\n",
      "用户: 那下一个数呢？\n",
      "助手: 斐波那契数列的每个数都是前两个数的和。前3个数是1、1、2，所以下一个数是1 + 2 = 3。\n"
     ]
    }
   ],
   "source": [
    "# 初始化 Chat 对象\n",
    "chat = Chat(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# 1. 简单问答 (不记录历史)\n",
    "answer = chat.ask(\"1+1=?\", update_history=False)\n",
    "print(f\"简单问答: {answer}\")\n",
    "\n",
    "# 2. 多轮对话\n",
    "chat.system(\"你是一个数学助手\")\n",
    "chat.user(\"斐波那契数列的前3个数是？\")\n",
    "resp = chat.get_response()\n",
    "print(f\"\\n用户: {chat.chat_log[-2]['content']}\")\n",
    "print(f\"助手: {resp.content}\")\n",
    "\n",
    "# 继续对话\n",
    "chat.user(\"那下一个数呢？\")\n",
    "resp = chat.get_response()\n",
    "print(f\"\\n用户: {chat.chat_log[-2]['content']}\")\n",
    "print(f\"助手: {resp.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e93914d",
   "metadata": {},
   "source": [
    "## 3. 批量对话\n",
    "\n",
    "使用 `batch_process_chat` 并发处理多个对话请求，适合数据标注场景。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68572f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原文: 你好，世界\n",
      "译文: Hello, world.\n",
      "--------------------\n",
      "原文: 今天天气不错\n",
      "译文: The weather is nice today.\n",
      "--------------------\n",
      "原文: 人工智能正在改变生活\n",
      "译文: Artificial intelligence is changing life.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 定义处理函数\n",
    "async def process_text(text):\n",
    "    chat = Chat()\n",
    "    # 可以在这里添加 system prompt\n",
    "    chat.system(\"请将这句话翻译成英文\")\n",
    "    await chat.async_ask(text)\n",
    "    return chat\n",
    "\n",
    "# 2. 准备数据\n",
    "texts = [\n",
    "    \"你好，世界\",\n",
    "    \"今天天气不错\",\n",
    "    \"人工智能正在改变生活\"\n",
    "]\n",
    "\n",
    "# 3. 批量处理 (nworker 控制并发数)\n",
    "chats = Chat.batch_process_chat(\n",
    "    texts,\n",
    "    process_text,\n",
    "    nworker=3,\n",
    "    checkpoint='chat_example.jsonl' # 用于保存中间结果，方便中断后处理\n",
    ")\n",
    "\n",
    "# 4. 查看结果\n",
    "for i, chat in enumerate(chats):\n",
    "    print(f\"原文: {texts[i]}\")\n",
    "    print(f\"译文: {chat.last_message}\")\n",
    "    print(\"-\" * 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
