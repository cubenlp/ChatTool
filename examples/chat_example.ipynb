{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat 对象使用示例\n",
    "\n",
    "这个示例展示了如何使用 Chat 对象进行对话管理，包括：\n",
    "- 从 .env 文件加载配置\n",
    "- 基本对话功能\n",
    "- 异步对话\n",
    "- 对话历史管理\n",
    "- 错误处理\n",
    "- 高级功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境准备和导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# 导入 chattool 相关模块\n",
    "from chattool.core.chattype import Chat\n",
    "from chattool.core.config import OpenAIConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 创建 Chat 对象\n",
    "\n",
    "使用环境变量自动配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chat 对象创建成功（使用环境变量配置）\n",
      "✅ Chat 对象创建成功（使用显式配置）\n"
     ]
    }
   ],
   "source": [
    "# 方法1: 使用默认配置（自动从环境变量读取）\n",
    "chat = Chat()\n",
    "print(\"✅ Chat 对象创建成功（使用环境变量配置）\")\n",
    "\n",
    "# 方法2: 使用显式配置\n",
    "config = OpenAIConfig(\n",
    "    api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    api_base=os.getenv('OPENAI_API_BASE'),\n",
    "    model=os.getenv('OPENAI_API_MODEL', 'gpt-3.5-turbo'),\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000\n",
    ")\n",
    "chat_with_config = Chat(config=config)\n",
    "print(\"✅ Chat 对象创建成功（使用显式配置）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 基本对话示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 第一轮对话 ===\n",
      "用户: 你好！请简单介绍一下自己。\n",
      "助手: 你好！我是一个友善的AI助手，可以帮助你回答问题，提供信息和解决问题。有什么可以帮到你的吗？\n",
      "Token使用: 99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 设置系统提示\n",
    "chat.system(\"你是一个友善的AI助手，请用简洁明了的方式回答问题。\")\n",
    "\n",
    "# 进行第一轮对话\n",
    "print(\"=== 第一轮对话 ===\")\n",
    "response1 = chat.user(\"你好！请简单介绍一下自己。\").get_response()\n",
    "print(f\"用户: 你好！请简单介绍一下自己。\")\n",
    "print(f\"助手: {response1.content}\")\n",
    "print(f\"Token使用: {response1.total_tokens}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 第二轮对话 ===\n",
      "用户: 能告诉我今天是星期几吗？\n",
      "助手: 当然！今天是星期二。有什么我可以帮助你的吗？\n",
      "Token使用: 147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 继续对话\n",
    "print(\"=== 第二轮对话 ===\")\n",
    "response2 = chat.user(\"能告诉我今天是星期几吗？\").get_response()\n",
    "print(f\"用户: 能告诉我今天是星期几吗？\")\n",
    "print(f\"助手: {response2.content}\")\n",
    "print(f\"Token使用: {response2.total_tokens}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 查看对话历史"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 对话历史 ===\n",
      "1. [SYSTEM]: 你是一个友善的AI助手，请用简洁明了的方式回答问题。\n",
      "2. [USER]: 你好！请简单介绍一下自己。\n",
      "3. [ASSISTANT]: 你好！我是一个友善的AI助手，可以帮助你回答问题，提供信息和解决问题。有什么可以帮到你的吗？\n",
      "4. [USER]: 能告诉我今天是星期几吗？\n",
      "5. [ASSISTANT]: 当然！今天是星期二。有什么我可以帮助你的吗？\n",
      "\n",
      "总消息数: 5\n",
      "最后一条消息: 当然！今天是星期二。有什么我可以帮助你的吗？\n"
     ]
    }
   ],
   "source": [
    "# 查看完整对话历史\n",
    "print(\"=== 对话历史 ===\")\n",
    "for i, message in enumerate(chat.chat_log):\n",
    "    role = message['role']\n",
    "    content = message['content'][:100] + '...' if len(message['content']) > 100 else message['content']\n",
    "    print(f\"{i+1}. [{role.upper()}]: {content}\")\n",
    "\n",
    "print(f\"\\n总消息数: {len(chat)}\")\n",
    "print(f\"最后一条消息: {chat.last_message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 便捷问答方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 便捷问答 ===\n",
      "问题: 请用一句话解释什么是人工智能？\n",
      "回答: 人工智能是一种模拟人类智慧和学习能力的技术。\n"
     ]
    }
   ],
   "source": [
    "# 使用 ask 方法进行快速问答\n",
    "print(\"=== 便捷问答 ===\")\n",
    "answer = chat.ask(\"请用一句话解释什么是人工智能？\")\n",
    "print(f\"问题: 请用一句话解释什么是人工智能？\")\n",
    "print(f\"回答: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 异步对话示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 异步对话示例 ===\n",
      "问题: Python中如何创建虚拟环境？\n",
      "回答: 你可以使用 `venv` 模块来创建Python虚拟环境。下面是一些简单的步骤：\n",
      "\n",
      "1. 打开命令行，进入你想要创建虚拟环境的目录。\n",
      "2. 运行以下命令来创建一个名为 `myenv` 的虚拟环境：\n",
      "\n",
      "```\n",
      "python -m venv myenv\n",
      "```\n",
      "\n",
      "3. 激活虚拟环境：\n",
      "\n",
      "在 Windows 上：\n",
      "\n",
      "```\n",
      "myenv\\Scripts\\activate\n",
      "```\n",
      "\n",
      "在 macOS 和 Linux 上：\n",
      "\n",
      "```\n",
      "source myenv/bin/activate\n",
      "```\n",
      "\n",
      "激活后，你会看到终端提示已进入虚拟环境。在虚拟环境中安装的包不会影响全局Python环境。\n"
     ]
    }
   ],
   "source": [
    "# 异步对话函数\n",
    "async def async_chat_example():\n",
    "    print(\"=== 异步对话示例 ===\")\n",
    "    \n",
    "    # 创建新的对话实例\n",
    "    async_chat = Chat()\n",
    "    async_chat.system(\"你是一个编程助手，请提供简洁的编程建议。\")\n",
    "    \n",
    "    # 异步获取响应\n",
    "    response = await async_chat.ask_async(\"Python中如何创建虚拟环境？\")\n",
    "    print(f\"问题: Python中如何创建虚拟环境？\")\n",
    "    print(f\"回答: {response}\")\n",
    "    \n",
    "    return async_chat\n",
    "\n",
    "# 运行异步示例\n",
    "async_chat = await async_chat_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 批量异步处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 批量异步处理 ===\n",
      "1. 问题: 什么是机器学习？\n",
      "   回答: 机器学习是一种人工智能的分支，利用数据和算法使计算机学习和改进性能。\n",
      "\n",
      "2. 问题: 什么是深度学习？\n",
      "   回答: 深度学习是一种基于人工神经网络模型、具有多层结构的机器学习方法。\n",
      "\n",
      "3. 问题: 什么是神经网络？\n",
      "   回答: 神经网络是一种模拟人脑神经元之间相互连接和通信方式的人工智能模型。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 批量处理多个问题\n",
    "async def batch_questions():\n",
    "    print(\"=== 批量异步处理 ===\")\n",
    "    \n",
    "    questions = [\n",
    "        \"什么是机器学习？\",\n",
    "        \"什么是深度学习？\",\n",
    "        \"什么是神经网络？\"\n",
    "    ]\n",
    "    \n",
    "    # 为每个问题创建独立的对话\n",
    "    tasks = []\n",
    "    for question in questions:\n",
    "        temp_chat = Chat()\n",
    "        temp_chat.system(\"请用一句话简洁回答问题。\")\n",
    "        task = temp_chat.ask_async(question)\n",
    "        tasks.append((question, task))\n",
    "    \n",
    "    # 并发执行所有任务\n",
    "    for i, (question, task) in enumerate(tasks):\n",
    "        answer = await task\n",
    "        print(f\"{i+1}. 问题: {question}\")\n",
    "        print(f\"   回答: {answer}\")\n",
    "        print()\n",
    "\n",
    "await batch_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 对话管理功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 对话管理 ===\n",
      "原对话消息数: 7\n",
      "复制对话消息数: 7\n",
      "\n",
      "复制对话中的新回答: 当然！我推荐《活着》这本书，它是余华的代表作品，描写了中国农村普通人的生活经历，充满了对生命的思考和感悟。非常值得一读！\n",
      "\n",
      "删除的消息: {'role': 'assistant', 'content': '人工智能是一种模拟人类智慧和学习能力的技术。'}\n",
      "删除后消息数: 6\n"
     ]
    }
   ],
   "source": [
    "# 对话复制\n",
    "print(\"=== 对话管理 ===\")\n",
    "copied_chat = chat.copy()\n",
    "print(f\"原对话消息数: {len(chat)}\")\n",
    "print(f\"复制对话消息数: {len(copied_chat)}\")\n",
    "\n",
    "# 在复制的对话中尝试不同的问题\n",
    "copied_response = copied_chat.ask(\"换个话题，你能推荐一本好书吗？\")\n",
    "print(f\"\\n复制对话中的新回答: {copied_response}\")\n",
    "\n",
    "# 删除最后一条消息\n",
    "removed_message = chat.pop()\n",
    "print(f\"\\n删除的消息: {removed_message}\")\n",
    "print(f\"删除后消息数: {len(chat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 调试和监控"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 调试和监控 ===\n",
      "对话历史:\n",
      "\n",
      "--------------------------------------------------\n",
      "SYSTEM\n",
      "--------------------------------------------------\n",
      "你是一个友善的AI助手，请用简洁明了的方式回答问题。\n",
      "\n",
      "--------------------------------------------------\n",
      "USER\n",
      "--------------------------------------------------\n",
      "你好！请简单介绍一下自己。\n",
      "\n",
      "--------------------------------------------------\n",
      "ASSISTANT\n",
      "--------------------------------------------------\n",
      "你好！我是一个友善的AI助手，可以帮助你回答问题，提供信息和解决问题。有什么可以帮到你的吗？\n",
      "\n",
      "--------------------------------------------------\n",
      "USER\n",
      "--------------------------------------------------\n",
      "能告诉我今天是星期几吗？\n",
      "\n",
      "--------------------------------------------------\n",
      "ASSISTANT\n",
      "--------------------------------------------------\n",
      "当然！今天是星期二。有什么我可以帮助你的吗？\n",
      "\n",
      "--------------------------------------------------\n",
      "USER\n",
      "--------------------------------------------------\n",
      "请用一句话解释什么是人工智能？\n",
      "\n",
      "最后一次响应详情:\n",
      "ID: chatcmpl-CR1HXbzaMfiDF8isi314lCtHNtwW7\n",
      "模型: gpt-3.5-turbo-0125\n",
      "创建时间: 1760555819\n",
      "完成原因: stop\n",
      "Token统计: {'prompt_tokens': 173, 'completion_tokens': 28, 'total_tokens': 201}\n"
     ]
    }
   ],
   "source": [
    "# 调试信息\n",
    "print(\"=== 调试和监控 ===\")\n",
    "\n",
    "# 打印对话历史\n",
    "print(\"对话历史:\")\n",
    "chat.print_log()\n",
    "\n",
    "# 获取最后一次响应的详细信息\n",
    "if chat.last_response:\n",
    "    print(\"\\n最后一次响应详情:\")\n",
    "    print(f\"ID: {chat.last_response.id}\")\n",
    "    print(f\"模型: {chat.last_response.model}\")\n",
    "    print(f\"创建时间: {chat.last_response.created}\")\n",
    "    print(f\"完成原因: {chat.last_response.finish_reason}\")\n",
    "    print(f\"Token统计: {chat.last_response.usage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. 异步对话示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n",
      "\n",
      "流式响应完成!\n",
      "完整内容长度: 34\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "chat = Chat().user('hi')\n",
    "async def stream_example():\n",
    "    # 使用异步流式响应\n",
    "    accumulated_content = \"\"\n",
    "    \n",
    "    async for response in chat.get_response_stream_async():\n",
    "        # 获取增量内容\n",
    "        if response.delta_content:\n",
    "            accumulated_content += response.delta_content\n",
    "            print(response.delta_content, end='', flush=True)\n",
    "        \n",
    "        # 检查是否完成\n",
    "        if response.finish_reason == 'stop':\n",
    "            print(\"\\n\\n流式响应完成!\")\n",
    "            break\n",
    "    \n",
    "    print(f\"完整内容长度: {len(accumulated_content)}\")\n",
    "\n",
    "# 运行异步函数\n",
    "asyncio.run(stream_example())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
