{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAIClient 使用示例\n",
    "\n",
    "这个示例展示了如何使用 OpenAIClient 与 OpenAI API 进行交互。\n",
    "OpenAIClient 继承自 HTTPClient，专门用于 OpenAI API 的聊天完成和嵌入功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入必要的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from chattool.core.request import OpenAIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chattool import debug_log\n",
    "debug_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置客户端\n",
    "\n",
    "首先需要设置OpenAI API密钥。请确保已经设置了环境变量 `OPENAI_API_KEY`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI客户端已创建\n"
     ]
    }
   ],
   "source": [
    "# 创建客户端实例\n",
    "client = OpenAIClient()\n",
    "print(\"OpenAI客户端已创建\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 基本的聊天完成示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 基本聊天完成示例 ===\n",
      "模型: gpt-3.5-turbo-0125\n",
      "回复: 人工智能（Artificial Intelligence，AI）是一种模拟人类智能思维和行为的技术。它涉及使用计算机系统来执行类似于人类智能的任务，例如学习、推理、问题解决和自主决策。人工智能的应用范围非常广泛，包括语音识别、图像识别、自然语言处理、机器学习、专家系统等领域。人工智能的发展对于改变我们的生活方式和\n",
      "使用的 tokens: {'prompt_tokens': 35, 'completion_tokens': 150, 'total_tokens': 185}\n"
     ]
    }
   ],
   "source": [
    "def basic_chat_completion():\n",
    "    \"\"\"基本的聊天完成示例\"\"\"\n",
    "    print(\"=== 基本聊天完成示例 ===\")    \n",
    "    try:\n",
    "        # 简单的聊天完成请求\n",
    "        response = client.chat_completion(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"你是一个有用的助手。\"},\n",
    "                {\"role\": \"user\", \"content\": \"请简单介绍一下人工智能。\"}\n",
    "            ],\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            max_tokens=150,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        print(f\"模型: {response.get('model', 'unknown')}\")\n",
    "        print(f\"回复: {response['choices'][0]['message']['content']}\")\n",
    "        print(f\"使用的 tokens: {response.get('usage', {})}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"聊天完成请求失败: {e}\")\n",
    "\n",
    "# 运行示例\n",
    "basic_chat_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 流式聊天完成示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 流式聊天完成示例 ===\n",
      "{'id': 'chatcmpl-CQv9TlJENqeN23UgfrWD36UPRTn5y', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '春风轻拂，温暖如春日的阳光\\n万物复苏，花开满园香气飘\\n小鸟鸣唱，欢乐传递无尽\\n春天来临，生机盎然无限'}, 'logprobs': None, 'finish_reason': 'stop'}], 'created': 1760532255, 'model': 'gpt-3.5-turbo-0125', 'object': 'chat.completion', 'usage': {'prompt_tokens': 23, 'completion_tokens': 77, 'total_tokens': 100}, 'system_fingerprint': 'fp_0165350fbb'}\n"
     ]
    }
   ],
   "source": [
    "def streaming_chat_completion():\n",
    "    \"\"\"流式聊天完成示例\"\"\"\n",
    "    print(\"=== 流式聊天完成示例 ===\")\n",
    "        \n",
    "    try:\n",
    "        # 流式聊天完成请求\n",
    "        res = client.chat_completion(\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": \"请写一首关于春天的短诗。\"}\n",
    "            ],\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            max_tokens=200,\n",
    "            temperature=0.8,\n",
    "            stream=True\n",
    "        )\n",
    "        print(res)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"流式聊天完成请求失败: {e}\")\n",
    "\n",
    "# 运行示例\n",
    "streaming_chat_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 异步聊天完成示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 异步聊天完成示例 ===\n",
      "异步回复: 异步编程是一种编程模式，允许程序在执行耗时操作时继续执行其他任务，而不必等待耗时操作完成。在异步编程中，程序可以发起一个耗时操作，然后继续执行其他任务，当耗时操作完成时，程序会得到通知或回调。这种方式可以提高程序的性能和响应速度，特别适用于需要处理大量I/O操作或网络请求的情况。\n",
      "\n",
      "常见的异步编程方式包括回调函数、Promise对象、async/await等。通过这些方式，可以更加方便地处理异步操作，避免程序在等待耗时操作时被阻塞。\n"
     ]
    }
   ],
   "source": [
    "async def async_chat_completion():\n",
    "    \"\"\"异步聊天完成示例\"\"\"\n",
    "    print(\"=== 异步聊天完成示例 ===\")\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # 异步聊天完成请求\n",
    "        response = await client.async_chat_completion(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"你是一个编程助手。\"},\n",
    "                {\"role\": \"user\", \"content\": \"请解释什么是异步编程？\"}\n",
    "            ],\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            max_tokens=200,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        \n",
    "        print(f\"异步回复: {response['choices'][0]['message']['content']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"异步聊天完成请求失败: {e}\")\n",
    "\n",
    "# 运行异步示例\n",
    "await async_chat_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 上下文管理器示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 上下文管理器示例 ===\n",
      "回复: 上下文管理器主要用于管理资源的分配和释放，确保资源能够正确被分配和及时释放，以避免资源泄漏或者错误的处理。通过使用上下文管理器，可以在进入和退出某个上下文的时候执行相应的代码，从而更好地控制资源的生命周期。\n",
      "客户端已自动关闭\n"
     ]
    }
   ],
   "source": [
    "def context_manager_example():\n",
    "    \"\"\"上下文管理器示例\"\"\"\n",
    "    print(\"=== 上下文管理器示例 ===\")\n",
    "    \n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\", \"your-api-key-here\")\n",
    "    \n",
    "    # 使用上下文管理器\n",
    "    with OpenAIClient(api_key=api_key) as client:\n",
    "        try:\n",
    "            response = client.chat_completion(\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": \"简单说一下上下文管理器的作用。\"}\n",
    "                ],\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                max_tokens=100\n",
    "            )\n",
    "            \n",
    "            print(f\"回复: {response['choices'][0]['message']['content']}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"请求失败: {e}\")\n",
    "    \n",
    "    print(\"客户端已自动关闭\")\n",
    "\n",
    "# 运行示例\n",
    "context_manager_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 异步上下文管理器示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 异步上下文管理器示例 ===\n",
      "异步回复: 异步上下文管理器具有以下优势：\n",
      "\n",
      "1. 提高并发性能：使用异步上下文管理器可以在异步程序中更有效地管理资源，避免资源的重复创建和释放，从而提高程序的并发性能。\n",
      "\n",
      "2. 异步代码简化：异步上下文管理器可以简化异步代码的编写，使代码更加清晰\n",
      "异步客户端已自动关闭\n"
     ]
    }
   ],
   "source": [
    "async def async_context_manager_example():\n",
    "    \"\"\"异步上下文管理器示例\"\"\"\n",
    "    print(\"=== 异步上下文管理器示例 ===\")\n",
    "    \n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\", \"your-api-key-here\")\n",
    "    \n",
    "    # 使用异步上下文管理器\n",
    "    async with OpenAIClient(api_key=api_key) as client:\n",
    "        try:\n",
    "            response = await client.async_chat_completion(\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": \"异步上下文管理器有什么优势？\"}\n",
    "                ],\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                max_tokens=100\n",
    "            )\n",
    "            \n",
    "            print(f\"异步回复: {response['choices'][0]['message']['content']}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"异步请求失败: {e}\")\n",
    "    \n",
    "    print(\"异步客户端已自动关闭\")\n",
    "\n",
    "# 运行异步示例\n",
    "await async_context_manager_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 错误处理示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 错误处理示例 ===\n",
      "API 密钥错误: HTTPStatusError: Client error '401 Authorization Required' for url 'https://api.chatanywhere.tech/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401\n",
      "无效模型错误: HTTPStatusError: Client error '401 Authorization Required' for url 'https://api.chatanywhere.tech/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401\n",
      "输入过长错误: HTTPStatusError: Client error '401 Authorization Required' for url 'https://api.chatanywhere.tech/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401\n"
     ]
    }
   ],
   "source": [
    "def error_handling_example():\n",
    "    \"\"\"错误处理示例\"\"\"\n",
    "    print(\"=== 错误处理示例 ===\")\n",
    "    \n",
    "    # 使用无效的 API 密钥\n",
    "    client = OpenAIClient(api_key=\"invalid-key\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat_completion(\n",
    "            messages=[{\"role\": \"user\", \"content\": \"测试\"}],\n",
    "            model=\"gpt-3.5-turbo\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"API 密钥错误: {type(e).__name__}: {e}\")\n",
    "    \n",
    "    # 测试无效模型\n",
    "    try:\n",
    "        response = client.chat_completion(\n",
    "            messages=[{\"role\": \"user\", \"content\": \"测试\"}],\n",
    "            model=\"invalid-model-name\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"无效模型错误: {type(e).__name__}: {e}\")\n",
    "    \n",
    "    # 测试超长输入\n",
    "    try:\n",
    "        long_message = \"测试\" * 10000  # 非常长的消息\n",
    "        response = client.chat_completion(\n",
    "            messages=[{\"role\": \"user\", \"content\": long_message}],\n",
    "            model=\"gpt-3.5-turbo\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"输入过长错误: {type(e).__name__}: {e}\")\n",
    "\n",
    "# 运行示例\n",
    "error_handling_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "这个notebook展示了OpenAIClient的主要功能：\n",
    "\n",
    "1. **基本聊天完成** - 与GPT模型进行对话\n",
    "2. **流式响应** - 实时接收模型输出\n",
    "3. **函数调用** - 让模型调用自定义函数\n",
    "4. **嵌入向量** - 生成文本的向量表示\n",
    "5. **异步操作** - 提高并发性能\n",
    "6. **上下文管理器** - 自动资源管理\n",
    "7. **错误处理** - 处理各种API错误\n",
    "\n",
    "### 使用注意事项\n",
    "\n",
    "1. **API密钥安全**: 确保API密钥的安全，不要在代码中硬编码\n",
    "2. **费用控制**: 注意token使用量，合理设置max_tokens参数\n",
    "3. **错误处理**: 始终包含适当的错误处理逻辑\n",
    "4. **异步优势**: 在需要处理多个请求时使用异步方法\n",
    "\n",
    "OpenAIClient提供了一个简洁而强大的接口来与OpenAI API交互，支持所有主要功能并提供了良好的错误处理和资源管理。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
